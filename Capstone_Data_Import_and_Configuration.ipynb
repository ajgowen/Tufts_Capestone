{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Import Data and Configureation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before populating the database create it in postgresql \n",
    "\n",
    " Scripts: \n",
    " CREATE DATABASE capstone;\n",
    " GRANT ALL PRIVILEGES ON DATABASE capstone TO username;\n",
    "\n",
    "Not nessasary but can also create the table columns example:\n",
    "\n",
    "CREATE TABLE weather_data (\n",
    "    YEAR VARCHAR(255),\n",
    "    STATION_ID VARCHAR(255),\n",
    "    DATE DATE,\n",
    "    ELEMENT VARCHAR(255),\n",
    "    DATA_VALUE FLOAT,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/Alex/Desktop/WeatherData/NOAAGlobalTemp\\Land.csv...\n",
      "Inserted 900 rows into the database.\n",
      "Processing C:/Users/Alex/Desktop/WeatherData/NOAAGlobalTemp\\Ocean.csv...\n",
      "Inserted 900 rows into the database.\n",
      "All files have been processed and inserted into the database.\n"
     ]
    }
   ],
   "source": [
    "# Gathering climate change data from noaaglobal average land temp and ocean temp\n",
    "# Move csv data files into postgresql \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Configuration\n",
    "CSV_DIR = \"C:/Users/Alex/Desktop/WeatherData/NOAAGlobalTemp\"  # Directory containing the extracted CSV files      # Update csv directory name \n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def process_csv_to_db(csv_dir, engine):\n",
    "    \"\"\"Read CSV files and load them into the PostgreSQL database.\"\"\"\n",
    "    for csv_file in os.listdir(csv_dir):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(csv_dir, csv_file)\n",
    "            print(f\"Processing {file_path}...\")\n",
    "\n",
    "            try:\n",
    "                # Read CSV into a DataFrame\n",
    "                df = pd.read_csv(file_path, usecols=[0, 1], header=None, names=[\n",
    "                    \"date\", \"anomaly\"\n",
    "                ])\n",
    "                \n",
    "                # Extract the file name to use as the land or Ocean distinction \n",
    "                LO = os.path.splitext(csv_file)[0]\n",
    "                \n",
    "                # Add the \"land_or_ocean\" column based on file name\n",
    "                df.insert(0, \"land_or_ocean\", LO)\n",
    "                \n",
    "                # Write to the PostgreSQL database                                                           # Update table name \n",
    "                table_name = \"raw_noaa_global_temps\"\n",
    "                df.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "                print(f\"Inserted {len(df)} rows into the database.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Ensure the CSV directory exists\n",
    "    if not os.path.exists(CSV_DIR):\n",
    "        print(f\"CSV directory '{CSV_DIR}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Process and load CSV files into the PostgreSQL database\n",
    "    process_csv_to_db(CSV_DIR, engine)\n",
    "    print(f\"All files have been processed and inserted into the database.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/Alex/Desktop/WeatherData/AGGI\\AGGI_co2_mm_mlo.csv...\n",
      "Inserted 802 rows into the database.\n",
      "All files have been processed and inserted into the database.\n"
     ]
    }
   ],
   "source": [
    "# Gathering climate change data from AGGI co2 \n",
    "# Move csv data files into postgresql \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Configuration\n",
    "CSV_DIR = \"C:/Users/Alex/Desktop/WeatherData/AGGI\"  # Directory containing the extracted CSV files      # Update csv directory name \n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def process_csv_to_db(csv_dir, engine):\n",
    "    \"\"\"Read CSV files and load them into the PostgreSQL database.\"\"\"\n",
    "    for csv_file in os.listdir(csv_dir):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(csv_dir, csv_file)\n",
    "            print(f\"Processing {file_path}...\")\n",
    "\n",
    "            try:\n",
    "                # Read CSV into a DataFrame\n",
    "                df = pd.read_csv(file_path, usecols=[0, 1,2,3,4,5,6], header=None, names=[\n",
    "                    \"date\", \"decimal_date\", \"average\", \"deseasonalized\", \"ndays\", \"sdev\", \"unc\"\n",
    "                ])\n",
    "                \n",
    "                # Write to the PostgreSQL database                                                           # Update table name \n",
    "                table_name = \"raw_aggi_co2_levels\"\n",
    "                df.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "                print(f\"Inserted {len(df)} rows into the database.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Ensure the CSV directory exists\n",
    "    if not os.path.exists(CSV_DIR):\n",
    "        print(f\"CSV directory '{CSV_DIR}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Process and load CSV files into the PostgreSQL database\n",
    "    process_csv_to_db(CSV_DIR, engine)\n",
    "    print(f\"All files have been processed and inserted into the database.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully inserted into the 'state_region' table.\n"
     ]
    }
   ],
   "source": [
    "# Add table assigning each state a climate region \n",
    "\n",
    "from sqlalchemy import create_engine, Table, MetaData, Column, String, CHAR\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Database configuration (as you provided)\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",  # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,         # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"  # Replace with your PostgreSQL database name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the 'state_region' table schema\n",
    "state_region = Table(\n",
    "    'state_region_mapping', metadata,\n",
    "    Column('state_code', CHAR(2), primary_key=True),  # Two-letter state code\n",
    "    Column('state_name', String(255)),\n",
    "    Column('region_name', String(255))\n",
    ")\n",
    "\n",
    "# Create the 'state_region' table if it doesn't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Data to insert (State abbreviation, state name, and region)\n",
    "regions_and_states = [\n",
    "    ('Northeast', [\n",
    "        ('CT', 'Connecticut'),\n",
    "        ('DE', 'Delaware'),\n",
    "        ('ME', 'Maine'),\n",
    "        ('MD', 'Maryland'),\n",
    "        ('MA', 'Massachusetts'),\n",
    "        ('NH', 'New Hampshire'),\n",
    "        ('NJ', 'New Jersey'),\n",
    "        ('NY', 'New York'),\n",
    "        ('PA', 'Pennsylvania'),\n",
    "        ('RI', 'Rhode Island'),\n",
    "        ('VT', 'Vermont'),\n",
    "    ]),\n",
    "    ('Upper Midwest', [\n",
    "        ('IA', 'Iowa'),\n",
    "        ('MI', 'Michigan'),\n",
    "        ('MN', 'Minnesota'),\n",
    "        ('WI', 'Wisconsin'),\n",
    "    ]),\n",
    "    ('Ohio Valley', [\n",
    "        ('IL', 'Illinois'),\n",
    "        ('IN', 'Indiana'),\n",
    "        ('KY', 'Kentucky'),\n",
    "        ('MO', 'Missouri'),\n",
    "        ('OH', 'Ohio'),\n",
    "        ('TN', 'Tennessee'),\n",
    "        ('WV', 'West Virginia'),\n",
    "    ]),\n",
    "    ('Southeast', [\n",
    "        ('AL', 'Alabama'),\n",
    "        ('FL', 'Florida'),\n",
    "        ('GA', 'Georgia'),\n",
    "        ('NC', 'North Carolina'),\n",
    "        ('SC', 'South Carolina'),\n",
    "        ('VA', 'Virginia'),\n",
    "    ]),\n",
    "    ('Northern Rockies and Plains', [\n",
    "        ('MT', 'Montana'),\n",
    "        ('NE', 'Nebraska'),\n",
    "        ('ND', 'North Dakota'),\n",
    "        ('SD', 'South Dakota'),\n",
    "        ('WY', 'Wyoming'),\n",
    "    ]),\n",
    "    ('South', [\n",
    "        ('AR', 'Arkansas'),\n",
    "        ('KS', 'Kansas'),\n",
    "        ('LA', 'Louisiana'),\n",
    "        ('MS', 'Mississippi'),\n",
    "        ('OK', 'Oklahoma'),\n",
    "        ('TX', 'Texas'),\n",
    "    ]),\n",
    "    ('Southwest', [\n",
    "        ('AZ', 'Arizona'),\n",
    "        ('CO', 'Colorado'),\n",
    "        ('NM', 'New Mexico'),\n",
    "        ('UT', 'Utah'),\n",
    "    ]),\n",
    "    ('Northwest', [\n",
    "        ('ID', 'Idaho'),\n",
    "        ('OR', 'Oregon'),\n",
    "        ('WA', 'Washington'),\n",
    "    ]),\n",
    "    ('West', [\n",
    "        ('CA', 'California'),\n",
    "        ('NV', 'Nevada'),\n",
    "    ]),\n",
    "    ('Alaska', [\n",
    "        ('AK', 'Alaska'),\n",
    "    ]),\n",
    "    ('Hawaii', [\n",
    "        ('HI', 'Hawaii'),\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Connect to the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Insert data into the state_region table\n",
    "for region, states_list in regions_and_states:\n",
    "    for state_code, state_name in states_list:\n",
    "        # Check if the state already exists to avoid duplicates\n",
    "        existing_state = session.query(state_region).filter_by(state_code=state_code).first()\n",
    "        if not existing_state:\n",
    "            session.execute(state_region.insert().values(state_code=state_code, state_name=state_name, region_name=region))\n",
    "\n",
    "# Commit the transaction\n",
    "session.commit()\n",
    "\n",
    "# Close the session\n",
    "session.close()\n",
    "\n",
    "print(\"Data successfully inserted into the 'state_region' table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Storm_Event_data from the NOAA website, fails due to the file not being accessable \n",
    "# Manually downloaded csv from https://www.arcgis.com/apps/dashboards/2f0a9f25eea3410ca0443bdce936f8e5 \n",
    "\n",
    "import os\n",
    "import ftplib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_ftp_links(webpage_url):\n",
    "    response = requests.get(webpage_url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].startswith('ftp://')]\n",
    "    \n",
    "    return links\n",
    "\n",
    "def download_ftp_file(ftp_url, download_path):\n",
    "    parsed_url = urlparse(ftp_url)\n",
    "    ftp_host = parsed_url.hostname\n",
    "    ftp_path = parsed_url.path\n",
    "    filename = os.path.basename(ftp_path)\n",
    "    \n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "    \n",
    "    local_file = os.path.join(download_path, filename)\n",
    "    \n",
    "    with ftplib.FTP(ftp_host) as ftp:\n",
    "        ftp.login()\n",
    "        with open(local_file, 'wb') as f:\n",
    "            ftp.retrbinary(f'RETR {ftp_path}', f.write)\n",
    "    \n",
    "    print(f'Downloaded: {filename}')\n",
    "\n",
    "def main(webpage_url, download_folder):\n",
    "    ftp_links = get_ftp_links(webpage_url)\n",
    "    \n",
    "    if not ftp_links:\n",
    "        print(\"No FTP links found on the page.\")\n",
    "        return\n",
    "    \n",
    "    for ftp_link in ftp_links:\n",
    "        try:\n",
    "            download_ftp_file(ftp_link, download_folder)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to download {ftp_link}: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    webpage_url = \"ftp://ftp.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles\"\n",
    "    download_folder = \"C:/Users/Alex/Desktop/WeatherData/Storm_Event_data\"\n",
    "    main(webpage_url, download_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/Alex/Desktop/WeatherData/Storm_Event_data\\NOAA_Storm_Events_Database_1950-2021_v2_9123639897772849412.csv...\n",
      "Inserted 1662829 rows into the database.\n",
      "All files have been processed and inserted into the database.\n"
     ]
    }
   ],
   "source": [
    "# Move Storm Event Data csv into postgresql \n",
    "# last recorded date is 2021-09\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Configuration\n",
    "CSV_DIR = \"C:/Users/Alex/Desktop/WeatherData/Storm_Event_data\"  # Directory containing the extracted CSV files      # Update csv directory name \n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def process_csv_to_db(csv_dir, engine):\n",
    "    \"\"\"Read CSV files and load them into the PostgreSQL database.\"\"\"\n",
    "    for csv_file in os.listdir(csv_dir):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(csv_dir, csv_file)\n",
    "            print(f\"Processing {file_path}...\")\n",
    "\n",
    "            try:\n",
    "                # Read CSV with the first row as column names\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Write to the PostgreSQL database\n",
    "                table_name = \"raw_storm_event_data\"                                                         # Update table name\n",
    "                df.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "                print(f\"Inserted {len(df)} rows into the database.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Ensure the CSV directory exists\n",
    "    if not os.path.exists(CSV_DIR):\n",
    "        print(f\"CSV directory '{CSV_DIR}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Process and load CSV files into the PostgreSQL database\n",
    "    process_csv_to_db(CSV_DIR, engine)\n",
    "    print(f\"All files have been processed and inserted into the database.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Inserted 1,662,829 rows into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'processed_storm_event_data' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Process Storm Event Data in postgresql so that the OBJECTID, state_codes, date, event_type are returned. \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_filtered_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "            SELECT \n",
    "                \"OBJECTID\" as event_id, \n",
    "                CASE \n",
    "                    WHEN \"STATE\" = 'ALABAMA' THEN 'AL'\n",
    "                    WHEN \"STATE\" = 'ALASKA' THEN 'AK'\n",
    "                    WHEN \"STATE\" = 'ARIZONA' THEN 'AZ'\n",
    "                    WHEN \"STATE\" = 'ARKANSAS' THEN 'AR'\n",
    "                    WHEN \"STATE\" = 'CALIFORNIA' THEN 'CA'\n",
    "                    WHEN \"STATE\" = 'COLORADO' THEN 'CO'\n",
    "                    WHEN \"STATE\" = 'CONNECTICUT' THEN 'CT'\n",
    "                    WHEN \"STATE\" = 'DELAWARE' THEN 'DE'\n",
    "                    WHEN \"STATE\" = 'FLORIDA' THEN 'FL'\n",
    "                    WHEN \"STATE\" = 'GEORGIA' THEN 'GA'\n",
    "                    WHEN \"STATE\" = 'HAWAII' THEN 'HI'\n",
    "                    WHEN \"STATE\" = 'IDAHO' THEN 'ID'\n",
    "                    WHEN \"STATE\" = 'ILLINOIS' THEN 'IL'\n",
    "                    WHEN \"STATE\" = 'INDIANA' THEN 'IN'\n",
    "                    WHEN \"STATE\" = 'IOWA' THEN 'IA'\n",
    "                    WHEN \"STATE\" = 'KANSAS' THEN 'KS'\n",
    "                    WHEN \"STATE\" = 'KENTUCKY' THEN 'KY'\n",
    "                    WHEN \"STATE\" = 'LOUISIANA' THEN 'LA'\n",
    "                    WHEN \"STATE\" = 'MAINE' THEN 'ME'\n",
    "                    WHEN \"STATE\" = 'MARYLAND' THEN 'MD'\n",
    "                    WHEN \"STATE\" = 'MASSACHUSETTS' THEN 'MA'\n",
    "                    WHEN \"STATE\" = 'MICHIGAN' THEN 'MI'\n",
    "                    WHEN \"STATE\" = 'MINNESOTA' THEN 'MN'\n",
    "                    WHEN \"STATE\" = 'MISSISSIPPI' THEN 'MS'\n",
    "                    WHEN \"STATE\" = 'MISSOURI' THEN 'MO'\n",
    "                    WHEN \"STATE\" = 'MONTANA' THEN 'MT'\n",
    "                    WHEN \"STATE\" = 'NEBRASKA' THEN 'NE'\n",
    "                    WHEN \"STATE\" = 'NEVADA' THEN 'NV'\n",
    "                    WHEN \"STATE\" = 'NEW HAMPSHIRE' THEN 'NH'\n",
    "                    WHEN \"STATE\" = 'NEW JERSEY' THEN 'NJ'\n",
    "                    WHEN \"STATE\" = 'NEW MEXICO' THEN 'NM'\n",
    "                    WHEN \"STATE\" = 'NEW YORK' THEN 'NY'\n",
    "                    WHEN \"STATE\" = 'NORTH CAROLINA' THEN 'NC'\n",
    "                    WHEN \"STATE\" = 'NORTH DAKOTA' THEN 'ND'\n",
    "                    WHEN \"STATE\" = 'OHIO' THEN 'OH'\n",
    "                    WHEN \"STATE\" = 'OKLAHOMA' THEN 'OK'\n",
    "                    WHEN \"STATE\" = 'OREGON' THEN 'OR'\n",
    "                    WHEN \"STATE\" = 'PENNSYLVANIA' THEN 'PA'\n",
    "                    WHEN \"STATE\" = 'RHODE ISLAND' THEN 'RI'\n",
    "                    WHEN \"STATE\" = 'SOUTH CAROLINA' THEN 'SC'\n",
    "                    WHEN \"STATE\" = 'SOUTH DAKOTA' THEN 'SD'\n",
    "                    WHEN \"STATE\" = 'TENNESSEE' THEN 'TN'\n",
    "                    WHEN \"STATE\" = 'TEXAS' THEN 'TX'\n",
    "                    WHEN \"STATE\" = 'UTAH' THEN 'UT'\n",
    "                    WHEN \"STATE\" = 'VERMONT' THEN 'VT'\n",
    "                    WHEN \"STATE\" = 'VIRGINIA' THEN 'VA'\n",
    "                    WHEN \"STATE\" = 'WASHINGTON' THEN 'WA'\n",
    "                    WHEN \"STATE\" = 'WEST VIRGINIA' THEN 'WV'\n",
    "                    WHEN \"STATE\" = 'WISCONSIN' THEN 'WI'\n",
    "                    WHEN \"STATE\" = 'WYOMING' THEN 'WY'\n",
    "                    ELSE \"STATE\"\n",
    "                END AS state_code,\n",
    "                CONCAT(\"YEAR\", CASE \n",
    "                    WHEN \"MONTH_NAME\" = 'January' THEN '01'\n",
    "                    WHEN \"MONTH_NAME\" = 'February' THEN '02'\n",
    "                    WHEN \"MONTH_NAME\" = 'March' THEN '03'\n",
    "                    WHEN \"MONTH_NAME\" = 'April' THEN '04'\n",
    "                    WHEN \"MONTH_NAME\" = 'May' THEN '05'\n",
    "                    WHEN \"MONTH_NAME\" = 'June' THEN '06'\n",
    "                    WHEN \"MONTH_NAME\" = 'July' THEN '07'\n",
    "                    WHEN \"MONTH_NAME\" = 'August' THEN '08'\n",
    "                    WHEN \"MONTH_NAME\" = 'September' THEN '09'\n",
    "                    WHEN \"MONTH_NAME\" = 'October' THEN '10'\n",
    "                    WHEN \"MONTH_NAME\" = 'November' THEN '11'\n",
    "                    WHEN \"MONTH_NAME\" = 'December' THEN '12'\n",
    "                    ELSE \"MONTH_NAME\"\n",
    "                END) AS date,\n",
    "                \"EVENT_TYPE\" as event_type\n",
    "            FROM raw_storm_event_data;\n",
    "        \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"processed_storm_event_data\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_filtered_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'climate_change_data_combined' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Process climate change data into one table containing both global temps and co2 levels \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_full_climate_change_data_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "            select land.date, global_land_temp, global_ocean_temp, co2_levels  from (\n",
    "(SELECT date, anomaly as global_land_temp FROM raw_noaa_global_temps where land_or_ocean = 'Land') as ocean\n",
    "join\n",
    "(SELECT date, anomaly as global_ocean_temp FROM raw_noaa_global_temps where land_or_ocean = 'Ocean') as land\n",
    "on land.date = ocean.date\n",
    "left join \n",
    "(SELECT date, deseasonalized as co2_levels FROM raw_aggi_co2_levels) as co2\n",
    "on land.date = co2.date\n",
    ");\n",
    "        \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"climate_change_data_combined\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_full_climate_change_data_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'event_climate_data_complete_part1' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Combine weather event table, state region mapping and climate change data into one final table\n",
    "# RAW DATA USED FOR CLIMATE CHAGE FACTORS \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_full_event_and_climate_data_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "            select climate_data.date as date, global_land_temp, global_ocean_temp, co2_levels, climate_data.state_code, region_name, event_type  from \n",
    "(select * from climate_change_data_combined,state_region_mapping) climate_data  -- cross joins the two tables to assign every date to every state\n",
    "left join\n",
    "(select state_code, date, event_type from processed_storm_event_data) as weather_event_data -- left joins to weather event table \n",
    "on climate_data.date = cast(weather_event_data.date as bigint)\n",
    "\tand climate_data.state_code = weather_event_data.state_code;\n",
    "        \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"event_climate_data_complete_part1\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_full_event_and_climate_data_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'event_climate_data_complete_part2' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Combine weather event table, state region mapping and climate change data into one final table\n",
    "# SMOOTHED CLIMATE CHANGE FACTORS SCRIPT \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_full_event_and_climate_data_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "            select climate_data.date as date, global_land_temp, global_ocean_temp, co2_levels, climate_data.state_code, region_name, event_type  from \n",
    "(select * from (SELECT \n",
    "    date,\n",
    "    SUBSTRING(CAST(date AS VARCHAR), 1, 4) AS year,\n",
    "    AVG(co2_levels) OVER (PARTITION BY SUBSTRING(CAST(date AS VARCHAR), 1, 4)) AS co2_levels,\n",
    "    AVG(global_land_temp) OVER (PARTITION BY SUBSTRING(CAST(date AS VARCHAR), 1, 4)) AS global_land_temp,\n",
    "    AVG(global_ocean_temp) OVER (PARTITION BY SUBSTRING(CAST(date AS VARCHAR), 1, 4)) AS global_ocean_temp\n",
    "FROM \n",
    "    climate_change_data_combined),state_region_mapping) climate_data  -- cross joins the two tables to assign every date to every state\n",
    "left join\n",
    "(select state_code, date, event_type from processed_storm_event_data) as weather_event_data -- left joins to weather event table \n",
    "on climate_data.date = cast(weather_event_data.date as bigint)\n",
    "\tand climate_data.state_code = weather_event_data.state_code;\n",
    "        \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"event_climate_data_complete_part2\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_full_event_and_climate_data_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'climate_change_data_best_fit_predictions' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# SCRIPT THAT CREATES THE BEST FIT CLIMATE CHANGE TABLES \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",  # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,  # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\",  # Replace with your PostgreSQL database name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def fetch_climate_change_table_as_df(table_name):\n",
    "    \"\"\"\n",
    "    Retrieves a table from the PostgreSQL database and returns it as a Pandas DataFrame.\n",
    "    Parameters:\n",
    "    - table_name (str): Name of the table to fetch.\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the table data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = text(f\"SELECT * FROM {table_name} where date >= 196001 and date <= 202012;\")\n",
    "            df = pd.read_sql(query, connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def best_fit_line(df, date_column, y_column):\n",
    "    \"\"\"\n",
    "    Applies linear regression to the given data and returns the predicted values.\n",
    "    \"\"\"\n",
    "    df_fit = df.copy()\n",
    "\n",
    "    # Handle null values in the y column\n",
    "    df_fit = df_fit.dropna(subset=[date_column,y_column])\n",
    "\n",
    "    # Convert date to YYMM format if needed\n",
    "    #df_fit['numeric_date'] = pd.to_datetime(df_fit[date_column].astype(str), errors='coerce').dt.strftime('%y%m').astype(float)\n",
    "\n",
    "    # Reshape the date column to 2D array for LinearRegression\n",
    "    #X = df_fit[['numeric_date']].values.reshape(-1, 1)\n",
    "    X = df_fit[[date_column]].values\n",
    "    y = df_fit[y_column].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Add predictions as a new column\n",
    "    df_fit[f'{y_column}_predicted'] = model.predict(X)\n",
    "\n",
    "    return df_fit\n",
    "\n",
    "def create_predictions_table(df, date_column, columns_to_predict, table_name):\n",
    "    \"\"\"\n",
    "    Creates a new table in the database with the predicted values for each column.\n",
    "    \"\"\"\n",
    "    # Apply linear regression for each column\n",
    "    for column in columns_to_predict:\n",
    "        df = best_fit_line(df, date_column, column)\n",
    "    \n",
    "    # Only keep the relevant columns (date and the predicted columns)\n",
    "    result_df = df[[date_column] + [f\"{col}_predicted\" for col in columns_to_predict]]\n",
    "\n",
    "    # Write the result dataframe to a new table in the database\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            result_df.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "            print(f\"Table '{table_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "def main():\n",
    "    table_name = \"climate_change_data_combined\"  # Replace with actual table name\n",
    "    new_table_name = \"climate_change_data_best_fit_predictions\"  # Replace with desired new table name\n",
    "    df_climate_change_data = fetch_climate_change_table_as_df(table_name)\n",
    "    \n",
    "    if df_climate_change_data is not None:\n",
    "        # Define the columns to predict\n",
    "        columns_to_predict = ['global_land_temp', 'global_ocean_temp', 'co2_levels']\n",
    "        \n",
    "        # Create predictions and store them in the database\n",
    "        create_predictions_table(df_climate_change_data, 'date', columns_to_predict, new_table_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'event_climate_data_complete_part3' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Combine weather event table, state region mapping and climate change data into one final table\n",
    "# BEST FIT LINE FOR CLIMATE CHAGE FACTORS \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with your PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_full_event_and_climate_data_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "            select climate_data.date as date, global_land_temp_predicted as global_land_temp, global_ocean_temp_predicted as global_ocean_temp, co2_levels_predicted as co2_levels, climate_data.state_code, region_name, event_type  from \n",
    "(select * from climate_change_data_best_fit_predictions,state_region_mapping) climate_data  -- cross joins the two tables to assign every date to every state\n",
    "left join\n",
    "(select state_code, date, event_type from processed_storm_event_data) as weather_event_data -- left joins to weather event table \n",
    "on climate_data.date = cast(weather_event_data.date as bigint)\n",
    "\tand climate_data.state_code = weather_event_data.state_code;\n",
    "        \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"event_climate_data_complete_part3\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_full_event_and_climate_data_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table '_input_table_1_dataset' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a testing table for the Model \n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",          # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,                 # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\"      # Replace with your PostgreSQL database name                              # Update DB Name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def create_testing_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Query to filter and transform data from the `weather_data` table\n",
    "            query = text(\"\"\"\n",
    "                        select date, global_land_temp, global_ocean_temp, co2_levels, state_code ,region_name, \n",
    "                            case when event_type in ('Flood','Drought','Tornado','Blizzard',\n",
    "                            'Ice Storm','Excessive Heat','Wildfire','Tropical Storm',\n",
    "                            'Tropical Depression','Frost/Freeze','Flash Flood') then event_type\n",
    "                            when event_type in ('Hurricane (Typhoon)','Hurricane') then 'Hurricane'\n",
    "                            else null end as event_type\n",
    "                        from (select * from event_climate_data_complete_part1 union all select * from event_climate_data_complete_part2 union all select * from event_climate_data_complete_part3 )\n",
    "                            where date >= 199601\n",
    "                            and date <= 202012\n",
    "                            and state_code not in ('AK','HI'); \n",
    "                         \"\"\")\n",
    "\n",
    "            # Execute query and fetch the transformed data into a DataFrame\n",
    "            df = pd.read_sql(query, connection)\n",
    "\n",
    "            # Create a new table to store the transformed data\n",
    "            new_table_name = \"_input_table\"                                                        # update new table name if needed \n",
    "            df.to_sql(new_table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Table '{new_table_name}' has been created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    create_testing_table()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year month  global_land_temp  global_ocean_temp  co2_levels state_code  \\\n",
      "0      1996    01              0.30               0.27      361.98         AL   \n",
      "1      1996    01              0.30               0.27      361.98         AR   \n",
      "2      1996    01              0.30               0.27      361.98         AZ   \n",
      "3      1996    01              0.30               0.27      361.98         CA   \n",
      "4      1996    01              0.30               0.27      361.98         CO   \n",
      "...     ...   ...               ...                ...         ...        ...   \n",
      "14395  2020    12              1.44               0.55      414.91         VT   \n",
      "14396  2020    12              1.44               0.55      414.91         WA   \n",
      "14397  2020    12              1.44               0.55      414.91         WI   \n",
      "14398  2020    12              1.44               0.55      414.91         WV   \n",
      "14399  2020    12              1.44               0.55      414.91         WY   \n",
      "\n",
      "                       region_name  weather_event_count  \n",
      "0                        Southeast                    2  \n",
      "1                            South                    1  \n",
      "2                        Southwest                    0  \n",
      "3                             West                    2  \n",
      "4                        Southwest                    0  \n",
      "...                            ...                  ...  \n",
      "14395                    Northeast                    1  \n",
      "14396                    Northwest                    1  \n",
      "14397                Upper Midwest                    1  \n",
      "14398                  Ohio Valley                    1  \n",
      "14399  Northern Rockies and Plains                    0  \n",
      "\n",
      "[14400 rows x 8 columns]\n",
      "DataFrame saved to 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Raw_Training_Data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# OUTPUTS A SQL QUERY TO CSV FILE \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "def save_dataframe_to_excel(df, output_path):\n",
    "    \"\"\"\n",
    "    Saves a pandas DataFrame to an Excel file with headers at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to save.\n",
    "    output_path (str): Full path (including filename) for the output Excel file.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame as an Excel file\n",
    "    df.to_excel(output_path, index=False, header=True)\n",
    "    print(f\"DataFrame saved to '{output_path}'\")\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",  # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,  # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone_db_testing\",  # Replace with your PostgreSQL database name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def fetch_table_as_df():\n",
    "    \"\"\"\n",
    "    Retrieves a table from the PostgreSQL database and returns it as a Pandas DataFrame\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the table data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            #query = text(f\"SELECT * FROM {table_name};\")\n",
    "\n",
    "            query = text(f\"\"\"\n",
    "            select SUBSTRING(cast(date as varchar), 1, 4) AS year, \n",
    "        SUBSTRING(cast(date as varchar), 5, 2) AS month, \n",
    "\t\tglobal_land_temp, \n",
    "        global_ocean_temp, \n",
    "        co2_levels, \n",
    "        state_code,  \n",
    "        region_name,\n",
    "\t\tcount(distinct(event_type)) as weather_event_count from _input_table_1_dataset\n",
    "group by 1,2,3,4,5,6,7\n",
    "        \"\"\")\n",
    "            df = pd.read_sql(query, connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    df = fetch_table_as_df()\n",
    "    \n",
    "    if df is not None:\n",
    "        print(df)\n",
    "\n",
    "    # Save to Excel file\n",
    "    save_dataframe_to_excel(df, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Raw_Training_Data.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state_code      state_name                  region_name\n",
      "0          CT     Connecticut                    Northeast\n",
      "1          DE        Delaware                    Northeast\n",
      "2          ME           Maine                    Northeast\n",
      "3          MD        Maryland                    Northeast\n",
      "4          MA   Massachusetts                    Northeast\n",
      "5          NH   New Hampshire                    Northeast\n",
      "6          NJ      New Jersey                    Northeast\n",
      "7          NY        New York                    Northeast\n",
      "8          PA    Pennsylvania                    Northeast\n",
      "9          RI    Rhode Island                    Northeast\n",
      "10         VT         Vermont                    Northeast\n",
      "11         IA            Iowa                Upper Midwest\n",
      "12         MI        Michigan                Upper Midwest\n",
      "13         MN       Minnesota                Upper Midwest\n",
      "14         WI       Wisconsin                Upper Midwest\n",
      "15         IL        Illinois                  Ohio Valley\n",
      "16         IN         Indiana                  Ohio Valley\n",
      "17         KY        Kentucky                  Ohio Valley\n",
      "18         MO        Missouri                  Ohio Valley\n",
      "19         OH            Ohio                  Ohio Valley\n",
      "20         TN       Tennessee                  Ohio Valley\n",
      "21         WV   West Virginia                  Ohio Valley\n",
      "22         AL         Alabama                    Southeast\n",
      "23         FL         Florida                    Southeast\n",
      "24         GA         Georgia                    Southeast\n",
      "25         NC  North Carolina                    Southeast\n",
      "26         SC  South Carolina                    Southeast\n",
      "27         VA        Virginia                    Southeast\n",
      "28         MT         Montana  Northern Rockies and Plains\n",
      "29         NE        Nebraska  Northern Rockies and Plains\n",
      "30         ND    North Dakota  Northern Rockies and Plains\n",
      "31         SD    South Dakota  Northern Rockies and Plains\n",
      "32         WY         Wyoming  Northern Rockies and Plains\n",
      "33         AR        Arkansas                        South\n",
      "34         KS          Kansas                        South\n",
      "35         LA       Louisiana                        South\n",
      "36         MS     Mississippi                        South\n",
      "37         OK        Oklahoma                        South\n",
      "38         TX           Texas                        South\n",
      "39         AZ         Arizona                    Southwest\n",
      "40         CO        Colorado                    Southwest\n",
      "41         NM      New Mexico                    Southwest\n",
      "42         UT            Utah                    Southwest\n",
      "43         ID           Idaho                    Northwest\n",
      "44         OR          Oregon                    Northwest\n",
      "45         WA      Washington                    Northwest\n",
      "46         CA      California                         West\n",
      "47         NV          Nevada                         West\n",
      "48         AK          Alaska                       Alaska\n",
      "49         HI          Hawaii                       Hawaii\n",
      "DataFrame saved to 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/state_mapping.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# OUTPUTS STATE AND REGION MAPPING TO A CSV FILE \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "def save_dataframe_to_excel(df, output_path):\n",
    "    \"\"\"\n",
    "    Saves a pandas DataFrame to an Excel file with headers at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to save.\n",
    "    output_path (str): Full path (including filename) for the output Excel file.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame as an Excel file\n",
    "    df.to_excel(output_path, index=False, header=True)\n",
    "    print(f\"DataFrame saved to '{output_path}'\")\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with your PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with your PostgreSQL password\n",
    "    \"host\": \"localhost\",  # Replace with your PostgreSQL host\n",
    "    \"port\": 5432,  # Replace with your PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone_db_testing\",  # Replace with your PostgreSQL database name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def fetch_table_as_df(table_name):\n",
    "    \"\"\"\n",
    "    Retrieves a table from the PostgreSQL database and returns it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - table_name (str): Name of the table to fetch.\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the table data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = text(f\"SELECT * FROM {table_name};\")\n",
    "\n",
    "            df = pd.read_sql(query, connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \n",
    "    table_name = \"state_region_mapping\"  # Replace with your actual table name\n",
    "    df = fetch_table_as_df(table_name)\n",
    "    \n",
    "    if df is not None:\n",
    "        print(df)\n",
    "\n",
    "    # Save to Excel file\n",
    "    save_dataframe_to_excel(df, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/state_mapping.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
