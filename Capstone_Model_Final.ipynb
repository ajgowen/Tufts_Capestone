{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING MODEL FUNCTIONS \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DEFINING FETCH TABLE FUNCTION\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "# DB Configuration\n",
    "DB_CONFIG = {\n",
    "    \"username\": \"agowen\",  # Replace with PostgreSQL username\n",
    "    \"password\": \"Capstone\",  # Replace with PostgreSQL password\n",
    "    \"host\": \"localhost\",  # Replace with PostgreSQL host\n",
    "    \"port\": 5432,  # Replace with PostgreSQL port (default: 5432)\n",
    "    \"database\": \"capstone\",  # Replace with PostgreSQL database name\n",
    "}\n",
    "\n",
    "# Connection string for PostgreSQL\n",
    "CONN_STRING = f\"postgresql://{DB_CONFIG['username']}:{DB_CONFIG['password']}@\" \\\n",
    "              f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Database setup\n",
    "engine = create_engine(CONN_STRING)\n",
    "\n",
    "def fetch_table_as_df(table_name,weather_event_list):\n",
    "    \"\"\"\n",
    "    Retrieves a table from the PostgreSQL database and returns it as a Pandas DataFrame.\n",
    "    Parameters:\n",
    "    - table_name (str): Name of the table to fetch.\n",
    "    - weather_event_list (str): Name of event to fetch information for\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the table data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = text(f\"\"\"\n",
    "            select year, \n",
    "\t\tmonth, \n",
    "\t\tglobal_land_temp, \n",
    "        global_ocean_temp, \n",
    "        co2_levels, \n",
    "        state_code,  \n",
    "        region_name,\n",
    "\t\tcount(distinct(event_type)) as weather_event_count from (\n",
    "select  SUBSTRING(cast(date as varchar), 1, 4) AS year, \n",
    "        SUBSTRING(cast(date as varchar), 5, 2) AS month, \n",
    "        global_land_temp, \n",
    "        global_ocean_temp, \n",
    "        co2_levels, \n",
    "        state_code,  \n",
    "        region_name,\n",
    "        case when event_type in ({weather_event_list}) then event_type\n",
    "\t\telse null end as event_type\n",
    "\t    from {table_name}\n",
    "        group by 1,2,3,4,5,6,7,8\n",
    ")group by 1,2,3,4,5,6,7\n",
    ";\n",
    "        \"\"\")\n",
    "            df = pd.read_sql(query, connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def preprocess_data(df,keep_columns):\n",
    "    \"\"\"Encodes categorical columns and scales numerical features.\"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    if not categorical_cols.empty:\n",
    "        encoder = OrdinalEncoder()\n",
    "        df[categorical_cols] = encoder.fit_transform(df[categorical_cols])\n",
    "    \n",
    "    drop_columns = [col for col in df.columns if col not in keep_columns]\n",
    "    X = df.drop(columns=drop_columns)\n",
    "    y = df[\"weather_event_count\"]\n",
    "    \n",
    "    return X, y, encoder\n",
    "\n",
    "def train_model(X, y,model_name=\"XGBClassifier\"):\n",
    "     \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    \n",
    "    # Count the number of 1's and 0's for weight calc\n",
    "    count_ones = (y == 1).sum()\n",
    "    count_zeros = (y == 0).sum()\n",
    "    weight = math.sqrt(count_zeros / count_ones)\n",
    "\n",
    "    model = XGBClassifier(booster='gbtree',use_label_encoder=False, eval_metric='logloss',eta=.1,random_state=42, scale_pos_weight = weight, max_depth = 20)\n",
    "    model.fit(X_train, y)\n",
    "        \n",
    "    XGBClassifier_Accurcy_kfold = (f\"{model_name} XGBClassifier Accuracy: \")\n",
    "    XGBClassifier_MAE_kfold = (f\"{model_name} XGBClassifier MAE: \")\n",
    "\n",
    "    return {\n",
    "        f\"MAE\": XGBClassifier_MAE_kfold,\n",
    "        f\"Accuracy\": XGBClassifier_Accurcy_kfold,\n",
    "        f\"Model\": model,\n",
    "        f\"Scaler\": scaler\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def run_all_weather_event_models(table_name, all_weather_events,keep_columns):\n",
    "    all_results = {}\n",
    "\n",
    "    for event in all_weather_events:\n",
    "        weather_events = f\"('{event}')\"\n",
    "        df = fetch_table_as_df(table_name, weather_events)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"No data for event: {event}. Skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            X, y, encoder = preprocess_data(df,keep_columns)\n",
    "            model_name = event.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\")\n",
    "            results = train_model(X, y, model_name=model_name)\n",
    "            \n",
    "            all_results[event] = {\n",
    "                \"MAE\": results[f\"MAE\"],\n",
    "                \"Accuracy\": results[f\"Accuracy\"],\n",
    "                \"Scaler\": results[f\"Scaler\"],\n",
    "                \"Model\": results[f\"Model\"],\n",
    "                \"Encoder\": encoder\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event '{event}': {e}\")\n",
    "    print(\"Finished Training Models\")\n",
    "    return all_results, X, y\n",
    "\n",
    "\n",
    "# PREDICTING\n",
    "\n",
    "def fetch_predicting_table_as_df(table_name):\n",
    "    \"\"\"\n",
    "    Retrieves a table from the PostgreSQL database and returns it as a Pandas DataFrame.\n",
    "    Parameters:\n",
    "    - table_name (str): Name of the table to fetch.\n",
    "    Returns:\n",
    "    - Pandas DataFrame containing the table data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = text(f\"SELECT SUBSTRING(cast(date as varchar), 1, 4) AS year, SUBSTRING(cast(date as varchar), 5, 2) AS month, global_land_temp, global_ocean_temp, co2_levels, state_code, region_name FROM {table_name};\")\n",
    "            df = pd.read_sql(query, connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_predict_data(df,encoder,keep_columns):\n",
    "    \"\"\"Encodes categorical columns and scales numerical features.\"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    if not categorical_cols.empty:\n",
    "        df[categorical_cols] = encoder.fit_transform(df[categorical_cols])\n",
    "    \n",
    "    drop_columns = [col for col in df.columns if col not in keep_columns]\n",
    "    X = df.drop(columns=drop_columns)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def predict_all_weather_event_models(table_name,training_results,keep_columns):\n",
    "    all_predicted_results = {}\n",
    "    event_list = list(training_results.keys())\n",
    "    df = fetch_predicting_table_as_df(table_name)\n",
    "    if df.empty:\n",
    "        print(f\"No predicting data\\n\")\n",
    "\n",
    "    for event in event_list:\n",
    "        \n",
    "        df_with_predictions = df.copy()\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        try:\n",
    "            X_predict = preprocess_predict_data(df_copy, training_results[event]['Encoder'],keep_columns)\n",
    "            scaler_predict = training_results[event]['Scaler']\n",
    "            model_predict = training_results[event]['Model']\n",
    "            X_predict_future_scaled = scaler_predict.transform(X_predict)\n",
    "            predicted_results = model_predict.predict(X_predict_future_scaled)\n",
    "            \n",
    "            df_with_predictions['predicted'] = predicted_results\n",
    "\n",
    "            all_predicted_results[event] = {\n",
    "                \"predictions\": df_with_predictions,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event '{event}': {e}\")\n",
    "    print(\"Finished Future Predictions\")\n",
    "    return all_predicted_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Models\n",
      "Finished Future Predictions\n"
     ]
    }
   ],
   "source": [
    "all_weather_events = [\n",
    "    'Flood', 'Drought', 'Tornado', 'Blizzard', 'Ice Storm',\n",
    "    'Excessive Heat', 'Wildfire', 'Tropical Storm',\n",
    "    'Hurricane', 'Tropical Depression', 'Frost/Freeze', 'Flash Flood'\n",
    "]\n",
    "\n",
    "#keep_columns = [\"year\",\"month\",\"global_land_temp\", \"global_ocean_temp\", \"co2_levels\", \"state_code\", \"region_name\"]\n",
    "#keep_columns = [\"month\",\"global_land_temp\", \"global_ocean_temp\", \"co2_levels\", \"state_code\", \"region_name\"]\n",
    "keep_columns = [\"global_land_temp\", \"global_ocean_temp\", \"co2_levels\", \"state_code\", \"region_name\"]\n",
    "#keep_columns = [\"global_land_temp\", \"global_ocean_temp\", \"co2_levels\"]\n",
    "\n",
    "# TRAINING \n",
    "results_by_events, X, y = run_all_weather_event_models(\"_input_table\",all_weather_events,keep_columns)\n",
    "\n",
    "# PREDICTING FUCTIONS\n",
    "all_predicted_results = predict_all_weather_event_models(\"_input_predicting_table\", results_by_events,keep_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETURN FEATURE IMPORTANCE OF A MODEL AND PLOT TOGETHER \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Collect importance data into a DataFrame\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "for event, result in results_by_events.items():\n",
    "    model = result[\"Model\"]\n",
    "    booster = model.get_booster()\n",
    "    importance = booster.get_score(importance_type='gain')\n",
    "    feature_map = {f\"f{i}\": col for i, col in enumerate(X.columns)} # Defines Column/Feature Names\n",
    "    importance_named = {feature_map[k]: v for k, v in importance.items()}\n",
    "    \n",
    "    # Create DataFrame for this event\n",
    "    event_df = pd.Series(importance_named, name=event)\n",
    "    importance_df = pd.concat([importance_df, event_df], axis=1)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "importance_df = importance_df.fillna(0)\n",
    "\n",
    "# Plot\n",
    "features = importance_df.index.tolist()\n",
    "events = importance_df.columns.tolist()\n",
    "x = np.arange(len(features))  # X-axis positions for features\n",
    "width = 0.9 / len(events)     # Bar width\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "\n",
    "# Plot a bar for each event\n",
    "for i, event in enumerate(events):\n",
    "    gains = importance_df[event]\n",
    "    bars = plt.bar(x + i * width, gains, width=width, label=event)\n",
    "    \n",
    "    # Add gain values above each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, height + 0.01,\n",
    "                     f\"{height:.1f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Labels and layout\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Gain\")\n",
    "plt.title(\"Feature Importance (Gain) by Event\", fontweight='bold')\n",
    "plt.xticks(x + width * (len(events) - 1) / 2, features, rotation=45, ha='right')\n",
    "plt.legend(title=\"Event\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table '_prediction_result_state_region' created successfully.\n",
      "DataFrame saved to 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Final Data Inputs/prediction_state_region.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# SCRIPT THAT UNIONS ALL PREDICTED RESULTS, adds a column for the event, AND SAVES IT TO SQL and csv file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "def union_tables_with_label(tables_dict):\n",
    "    df_list = []\n",
    "\n",
    "    for event in tables_dict:\n",
    "        table = tables_dict[event][\"predictions\"]\n",
    "\n",
    "        df_copy = table.copy()\n",
    "        df_copy['event_name'] = event  # Add new column with dictionary key as the source label\n",
    "        df_list.append(df_copy)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def save_dataframe_to_excel(df, output_path):\n",
    "    \"\"\"\n",
    "    Saves a pandas DataFrame to an Excel file with headers at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to save.\n",
    "    output_path (str): Full path (including filename) for the output Excel file.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame as an Excel file\n",
    "    df.to_excel(output_path, index=False, header=True)\n",
    "    print(f\"DataFrame saved to '{output_path}'\")\n",
    "\n",
    "def create_predictions_table(predcition_dict):\n",
    "    \"\"\"\n",
    "    Creates a new table in the database with the predicted values for each column.\n",
    "    \"\"\"\n",
    "    #table_name = f\"_prediction_result_year_month_state_region\"\n",
    "    #table_name = f\"_prediction_result_month_state_region\"\n",
    "    table_name = f\"_prediction_result_state_region\"\n",
    "    #table_name = f\"_prediction_result_no_extra_features\"\n",
    "    # Write the result dataframe to a new table in the database\n",
    "\n",
    "    unioned_tables = union_tables_with_label(predcition_dict)\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            unioned_tables.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "            print(f\"Table '{table_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "    # Save to Excel file\n",
    "    #save_dataframe_to_excel(unioned_tables, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Final Data Inputs/prediction_results_year_month_state_region.xlsx')\n",
    "    #save_dataframe_to_excel(unioned_tables, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Final Data Inputs/prediction_results_month_state_region.xlsx')\n",
    "    save_dataframe_to_excel(unioned_tables, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Final Data Inputs/prediction_state_region.xlsx')\n",
    "    #save_dataframe_to_excel(unioned_tables, 'C:/Users/Alex/Desktop/Home_Documents/_Tufts/DS-288/Data/Final Data Inputs/prediction_results_no_extra_features.xlsx')\n",
    "\n",
    "def main():\n",
    "\n",
    "    create_predictions_table(all_predicted_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
